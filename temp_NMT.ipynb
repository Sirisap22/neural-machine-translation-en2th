{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "temp-NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPvBVLLhb+/18vRffVzljr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirisap22/neural-machine-translation-en2th/blob/main/temp_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ynUFuotCke"
      },
      "source": [
        "# Import Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys38ggjaKh6H"
      },
      "source": [
        "#!pip install torchtext==0.9.0\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, BucketIterator, Dataset, Example, TabularDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy, random"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td57SSGUtK2q",
        "outputId": "1ffd98e2-47ed-43a6-852c-f0e578c1c558"
      },
      "source": [
        "# tokenizer for thai language\n",
        "def installPyThaiNLP():\n",
        "    !pip install https://github.com/PyThaiNLP/pythainlp/archive/dev.zip\n",
        "    !pip install epitran\n",
        "    !pip install sklearn_crfsuite\n",
        "installPyThaiNLP()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/PyThaiNLP/pythainlp/archive/dev.zip\n",
            "\u001b[?25l  Downloading https://github.com/PyThaiNLP/pythainlp/archive/dev.zip\n",
            "\u001b[K     - 12.7MB 126kB/s\n",
            "\u001b[?25hCollecting python-crfsuite>=0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp==2.3.0b1) (2.23.0)\n",
            "Collecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/af/cd/1ce3d93818cdeda0446b8033d21e5f32daeb3a866bbafd878a9a62058a9c/tinydb-4.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==2.3.0b1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==2.3.0b1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==2.3.0b1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp==2.3.0b1) (1.24.3)\n",
            "Building wheels for collected packages: pythainlp\n",
            "  Building wheel for pythainlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pythainlp: filename=pythainlp-2.3.0b1-cp37-none-any.whl size=11006868 sha256=2e8f60e2d593a03c58577b6963dbbbc73ec08c8082b51068d01dc40629d79196\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-onr4hjfw/wheels/79/4e/1e/26f3198c6712ecfbee92928ed1dde923a078da3d222401cc78\n",
            "Successfully built pythainlp\n",
            "Installing collected packages: python-crfsuite, tinydb, pythainlp\n",
            "Successfully installed pythainlp-2.3.0b1 python-crfsuite-0.9.7 tinydb-4.4.0\n",
            "Collecting epitran\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/de/799795f6fe86f66c31d5cba1240317e522054825763dbfa8d9dc7e373842/epitran-1.9-py2.py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 16.4MB/s \n",
            "\u001b[?25hCollecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 37.7MB/s \n",
            "\u001b[?25hCollecting panphon>=0.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/25/935f443f0a2cce5d7a4b6b0d9101c990a6f3c74702c02287d4addd3fe009/panphon-0.17-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from epitran) (2019.12.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from epitran) (54.1.2)\n",
            "Collecting unicodecsv\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon>=0.16->epitran) (3.13)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from panphon>=0.16->epitran) (0.5.3)\n",
            "Collecting munkres\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ab/0301c945a704218bc9435f0e3c88884f6b19ef234d8899fb47ce1ccfd0c9/munkres-1.1.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from panphon>=0.16->epitran) (1.19.5)\n",
            "Building wheels for collected packages: marisa-trie, unicodecsv\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp37-cp37m-linux_x86_64.whl size=860545 sha256=8fe931ffdf0be8d6e1ae543fc29b75ddd40829395a115b28692dba4712171da6\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp37-none-any.whl size=10768 sha256=b9438010cd2eaaa353175ccd31b940044eb0499db194af73abfd7dc865de8e8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "Successfully built marisa-trie unicodecsv\n",
            "Installing collected packages: marisa-trie, munkres, unicodecsv, panphon, epitran\n",
            "Successfully installed epitran-1.9 marisa-trie-0.7.5 munkres-1.1.4 panphon-0.17 unicodecsv-0.14.1\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Installing collected packages: sklearn-crfsuite\n",
            "Successfully installed sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOk5XZHUUjoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd507997-e597-4163-ca79-d24837cb8509"
      },
      "source": [
        "def runOnceNltk():\n",
        "    import nltk\n",
        "    nltk.download('punkt')\n",
        "runOnceNltk()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGh68P-lufLP"
      },
      "source": [
        "from pythainlp import word_tokenize as tokenize_thai\n",
        "from nltk.tokenize import word_tokenize as tokenize_eng\n",
        "def tokenizeThai(s):\n",
        "    return tokenize_thai(s, keep_whitespace=False)\n",
        "def tokenizeEng(s):\n",
        "    return tokenize_eng(s)\n"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Crn3O2MRmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e52bdd22-fc83-4f75-a913-15ce1d2eb5c1"
      },
      "source": [
        "# import data\n",
        "\n",
        "df = pd.read_csv('generated_reviews_yn.csv')\n",
        "df.head()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We are trying to use them on our Samsung Smart...</td>\n",
              "      <td>เรากำลังพยายามใช้พวกเขาบน Samsung Smart TV ของเรา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This thing will not work with Mac OSX 10.4.7.1.</td>\n",
              "      <td>สิ่งนี้จะไม่ทำงานกับ Mac OSX 10.4.7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We are very happy with our Dyson DC25.</td>\n",
              "      <td>เรามีความสุขมากกับ Dyson DC25 ของเรา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It doesn't work with Skype.</td>\n",
              "      <td>มันไม่ทำงานกับ Skype</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'll be looking at Cisco next.</td>\n",
              "      <td>ฉันจะดู Cisco ต่อไป</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             en_text                                            th_text\n",
              "0  We are trying to use them on our Samsung Smart...  เรากำลังพยายามใช้พวกเขาบน Samsung Smart TV ของเรา\n",
              "1    This thing will not work with Mac OSX 10.4.7.1.              สิ่งนี้จะไม่ทำงานกับ Mac OSX 10.4.7.1\n",
              "2             We are very happy with our Dyson DC25.               เรามีความสุขมากกับ Dyson DC25 ของเรา\n",
              "3                        It doesn't work with Skype.                               มันไม่ทำงานกับ Skype\n",
              "4                     I'll be looking at Cisco next.                                ฉันจะดู Cisco ต่อไป"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FLx7rJ3-0RmT",
        "outputId": "06334e43-2e97-4f8c-af02-02f2a4b7bb40"
      },
      "source": [
        "encode = ''\n",
        "with open('thai_websites.csv') as f:\n",
        "   encode = f.encoding\n",
        "df2 = pd.read_csv('thai_websites.csv', encoding=encode)\n",
        "df2.head()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en_text</th>\n",
              "      <th>th_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CLARINS This intensive replenishing cream hel...</td>\n",
              "      <td>คืนความยืดหยุ่นให้ผิวที่ร่วงโรยตามวัย จากการเป...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ONLY@CENTRAL Color : Almond Size : 32 A UK Ca...</td>\n",
              "      <td>ONLY@CENTRAL สี : เบจไซส์ : 32 A UK หมายเหตุ:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ONLY@CENTRAL Color : Almond Size : 32 B UK Ca...</td>\n",
              "      <td>ONLY@CENTRAL สี : เบจไซส์ : 32 B UK หมายเหตุ:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ONLY@CENTRAL Color : Almond Size : 32 C UK Ca...</td>\n",
              "      <td>ONLY@CENTRAL สี : เบจไซส์ : 32 C UK หมายเหตุ:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ONLY@CENTRAL Color : Almond Size : 34 A UK Ca...</td>\n",
              "      <td>ONLY@CENTRAL สี : เบจไซส์ : 34 A UK หมายเหตุ:...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             en_text                                            th_text\n",
              "0   CLARINS This intensive replenishing cream hel...  คืนความยืดหยุ่นให้ผิวที่ร่วงโรยตามวัย จากการเป...\n",
              "1   ONLY@CENTRAL Color : Almond Size : 32 A UK Ca...   ONLY@CENTRAL สี : เบจไซส์ : 32 A UK หมายเหตุ:...\n",
              "2   ONLY@CENTRAL Color : Almond Size : 32 B UK Ca...   ONLY@CENTRAL สี : เบจไซส์ : 32 B UK หมายเหตุ:...\n",
              "3   ONLY@CENTRAL Color : Almond Size : 32 C UK Ca...   ONLY@CENTRAL สี : เบจไซส์ : 32 C UK หมายเหตุ:...\n",
              "4   ONLY@CENTRAL Color : Almond Size : 34 A UK Ca...   ONLY@CENTRAL สี : เบจไซส์ : 34 A UK หมายเหตุ:..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdnMHpkNt49i"
      },
      "source": [
        "thai = Field(tokenize=tokenizeThai , init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "english = Field(tokenize=tokenizeEng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDAdLYMId5gx"
      },
      "source": [
        "fields = [('en_text', english), ('th_text', thai)]\n",
        "train_data, valid_data = TabularDataset.splits(\n",
        "    path = \"./\",\n",
        "    train = 'generated_reviews_yn.csv',\n",
        "    test = 'thai_websites.csv',\n",
        "    format = 'csv', \n",
        "    fields = fields\n",
        ")"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua6BHJdfyeal"
      },
      "source": [
        "train_data =  DataFrameDataset(df, {'en_text': english, 'th_text': thai})\n",
        "valid_data = DataFrameDataset(df2, {'en_text': english, 'th_text': thai})"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8cZIGhXzC6E",
        "outputId": "58bb68af-0f3e-4552-8c9b-4156afbece51"
      },
      "source": [
        "train_data, valid_data, len(train_data), len(valid_data)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torchtext.legacy.data.dataset.TabularDataset at 0x7ff3113f0fd0>,\n",
              " <torchtext.legacy.data.dataset.TabularDataset at 0x7ff3113f0390>,\n",
              " 280209,\n",
              " 120281)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blpp5bmSxPPS"
      },
      "source": [
        "thai.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=3)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pvn12vDzYGG",
        "outputId": "b4eebc1d-0f03-4432-a8cc-adefdc0bd4d4"
      },
      "source": [
        "print(f'Unique tokens in source (en) vocabulary: {len(english.vocab)}')\n",
        "print(f'Unique tokens in target (th) vocabulary: {len(thai.vocab)}')"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (en) vocabulary: 10004\n",
            "Unique tokens in target (th) vocabulary: 10004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byl8Bt_ezu9O"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-DPY7V44EsW"
      },
      "source": [
        "train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), \n",
        "                                                                      batch_size = BATCH_SIZE, \n",
        "                                                                      sort_within_batch=True,\n",
        "                                                                      sort_key=lambda x: len(x.en_text),\n",
        "                                                                      device = device)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKBFClvc7_uQ",
        "outputId": "d8bf86ba-f935-48dd-de6f-f5d185df3939"
      },
      "source": [
        "max_len_thai = []\n",
        "max_len_eng = []\n",
        "count = 0\n",
        "for src, trg in zip(train_data.en_text, train_data.th_text):\n",
        "  max_len_thai.append(len(src))\n",
        "  max_len_eng.append(len(trg))\n",
        "  if count < 10 :\n",
        "    print(\"English - \",src, \" Length - \", len(src))\n",
        "    print(\"thai - \",trg, \" Length - \", len(trg))\n",
        "    print()\n",
        "  count += 1\n",
        "print(\"Maximum Length of English Sentence {} and Thai Sentence {} in the dataset\".format(max(max_len_eng),max(max_len_thai)))\n",
        "print(\"Minimum Length of English Sentence {} and Thai Sentence {} in the dataset\".format(min(max_len_eng),min(max_len_thai)))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English -  ['en_text']  Length -  1\n",
            "thai -  ['th', '_', 'text']  Length -  3\n",
            "\n",
            "English -  ['we', 'are', 'trying', 'to', 'use', 'them', 'on', 'our', 'samsung', 'smart', 'tv', '.']  Length -  12\n",
            "thai -  ['เรา', 'กำลัง', 'พยายาม', 'ใช้', 'พวกเขา', 'บน', 'Samsung', 'Smart', 'TV', 'ของ', 'เรา']  Length -  11\n",
            "\n",
            "English -  ['this', 'thing', 'will', 'not', 'work', 'with', 'mac', 'osx', '10.4.7.1', '.']  Length -  10\n",
            "thai -  ['สิ่ง', 'นี้', 'จะ', 'ไม่', 'ทำงาน', 'กับ', 'Mac', 'OSX', '10.4.7.1']  Length -  9\n",
            "\n",
            "English -  ['we', 'are', 'very', 'happy', 'with', 'our', 'dyson', 'dc25', '.']  Length -  9\n",
            "thai -  ['เรา', 'มีความสุข', 'มาก', 'กับ', 'Dyson', 'DC', '25', 'ของ', 'เรา']  Length -  9\n",
            "\n",
            "English -  ['it', 'does', \"n't\", 'work', 'with', 'skype', '.']  Length -  7\n",
            "thai -  ['มัน', 'ไม่', 'ทำงาน', 'กับ', 'Skype']  Length -  5\n",
            "\n",
            "English -  ['i', \"'ll\", 'be', 'looking', 'at', 'cisco', 'next', '.']  Length -  8\n",
            "thai -  ['ฉัน', 'จะ', 'ดู', 'Cisco', 'ต่อไป']  Length -  5\n",
            "\n",
            "English -  ['however', ',', 'i', 'know', 'rowling', 'can', 'do', 'better', '!']  Length -  9\n",
            "thai -  ['อย่างไรก็ตาม', 'ฉัน', 'รู้', 'ว่า', 'Rowling', 'สามารถ', 'ทำได้', 'ดีกว่า', '!']  Length -  9\n",
            "\n",
            "English -  ['i', 'am', 'using', 'this', 'on', 'my', 'd3200', ',', 'which', 'has', 'already', 'been', 'upgraded', 'with', 'the', '55-200mm', 'vr', 'ii', '.']  Length -  19\n",
            "thai -  ['ฉัน', 'ใช้', 'สิ่ง', 'นี้', 'กับ', 'D', '3200', 'ของ', 'ฉัน', 'ซึ่ง', 'ได้รับ', 'การ', 'อัพเกรด', 'ด้วย', '55', '-', '200', 'mm', 'VR', 'II', 'แล้ว']  Length -  21\n",
            "\n",
            "English -  ['i', 'was', 'expecting', 'better', 'from', 'chris', 'rock', '!']  Length -  8\n",
            "thai -  ['ฉัน', 'คาดหวัง', 'ได้', 'ดีกว่า', 'จาก', 'Chris', 'Rock', '!']  Length -  8\n",
            "\n",
            "English -  ['it', 'comes', 'with', 'vga', ',', 'dvi', ',', 'and', 'three', 'hdmi', '.']  Length -  11\n",
            "thai -  ['มัน', 'มา', 'พร้อมกับ', 'VGA', ',', 'DVI', 'และ', 'สาม', 'HDMI']  Length -  9\n",
            "\n",
            "Maximum Length of English Sentence 96 and Thai Sentence 100 in the dataset\n",
            "Minimum Length of English Sentence 3 and Thai Sentence 1 in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLcoTXIY8pgX",
        "outputId": "58448c71-6934-4c96-8cf7-87f14dd9cff8"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    \n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "\n",
        "    return hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = len(english.vocab)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
        "print(encoder_lstm)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(10004, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wccv-DMh-wDI",
        "outputId": "f1e31498-655d-4063-dff8-8cdc641ee2cb"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "\n",
        "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
        "    predictions = self.fc(outputs)\n",
        "\n",
        "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(thai.vocab)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = len(thai.vocab)\n",
        "\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "print(decoder_lstm)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(10004, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  (fc): Linear(in_features=1024, out_features=10004, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ-4xPwHBgFS"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC71idvF_gNB",
        "outputId": "ed27a71a-5b81-406c-f217-3875b61c8cec"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    # Shape - Source : (10, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (14, 32) [(Sentence length Thai + some padding), Number of Sentences]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(thai.vocab)\n",
        "    \n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n",
        "\n",
        "learning_rate = 0.001\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = thai.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (Encoder_LSTM): EncoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(10004, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  )\n",
            "  (Decoder_LSTM): DecoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(10004, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "    (fc): Linear(in_features=1024, out_features=10004, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_32KCDyBqJv"
      },
      "source": [
        "\n",
        "def translate_sentence(model, sentence, english, thai, device, max_length=50):\n",
        "\n",
        "    if type(sentence) == str:\n",
        "        tokens = tokenizeEng(sentence)\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    tokens.insert(0, english.init_token)\n",
        "    tokens.append(english.eos_token)\n",
        "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "    outputs = [thai.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == thai.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [thai.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JkDxIg4CM5L"
      },
      "source": [
        "def bleu(data, model, english, thai, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"en_text\"]\n",
        "        trg = vars(example)[\"th_text\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, english, thai, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
        "    print('saving')\n",
        "    print()\n",
        "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
        "    torch.save(state, '/content/checkpoint-NMT')\n",
        "    torch.save(model.state_dict(),'/content/checkpoint-NMT-SD')"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-pzgB5cBcG6"
      },
      "source": [
        "epoch_loss = 0.0\n",
        "num_epochs = 100\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "sentence1 = \"This is a dog\"\n",
        "ts1 = []"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3E5JgQ9jbG"
      },
      "source": [
        "def loadCheckpoint():\n",
        "    global epoch_loss, best_epoch, best_loss, model, optimizer, torch\n",
        "    checkpoint_NMT = torch.load('./checkpoint-NMT')\n",
        "    model.load_state_dict(checkpoint_NMT['model'].state_dict())\n",
        "    optimizer.load_state_dict(checkpoint_NMT['optimizer'])\n",
        "    best_epoch = checkpoint_NMT['epoch']\n",
        "    best_loss = checkpoint_NMT['best_loss']\n",
        "    epoch_loss = checkpoint_NMT['best_loss']\n",
        "    torch.set_rng_state(checkpoint_NMT['rng_state'])\n",
        "loadCheckpoint()"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP3NgF5iBhpb",
        "outputId": "03119b3e-38d1-4815-fce1-21fd51356b87"
      },
      "source": [
        "epoch_loss, best_loss, best_epoch"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37662.80535519123, 37662.80535519123, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "QYN3Vp8x_9WL",
        "outputId": "77b01646-1de0-42f7-b05d-8928a8b3cc05"
      },
      "source": [
        "continue_epoch = best_epoch + 1\n",
        "for epoch in range(continue_epoch ,num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  translated_sentence1 = translate_sentence(model, sentence1, english, thai, device, max_length=50)\n",
        "  print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n",
        "  ts1.append(translated_sentence1)\n",
        "\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    input = batch.en_text.to(device)\n",
        "    target = batch.th_text.to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using bp \n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss / len(train_iterator))\n",
        "\n",
        "#score = bleu(valid_data[1:100], model, english, thai, device)\n",
        "#print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 100\n",
            "Translated example sentence 1: \n",
            " ['Joe', 'หนังสือประวัติศาสตร์', 'ต้อ', '\"?', 'คล้อง', 'ต้อ', 'แคตตาล็อก', 'การสืบสวน', 'เกียร์', 'Ethernet', 'เกียร์', 'บอก', 'หวือหวา', 'แม้แต่', '!\"', '!\"', 'อัตชีวประวัติ', 'กี้', 'กี้', 'เนื่องเพราะ', 'สหภาพโซเวียต', 'เนื่องเพราะ', 'สหภาพโซเวียต', 'pdf', 'pdf', 'pdf', '52', '52', 'เด็กหญิง', 'Iron', 'ตัก', 'ตัก', 'ก็ได้', 'ก็ได้', 'ก็ได้', 'กี้', 'กี้', 'จุดสิ้นสุด', 'มีรส', 'มีรส', 'iBook', 'มีรส', 'iBook', 'กําเนิด', 'เอื้อมมือ', 'มีรส', 'มีรส', 'เอื้อมมือ', 'มีรส', 'Crichton']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 3.5097827911376953\n",
            "\n",
            "Epoch - 2 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 3.948538064956665\n",
            "\n",
            "Epoch - 3 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<eos>']\n",
            "Epoch_Loss - 3.565189838409424\n",
            "\n",
            "Epoch - 4 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', 'ไม่', '<eos>']\n",
            "Epoch_Loss - 4.102074146270752\n",
            "\n",
            "Epoch - 5 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', 'มี', '<unk>', 'แผ่', '<eos>']\n",
            "Epoch_Loss - 2.3757035732269287\n",
            "\n",
            "Epoch - 6 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', 'ฉัน', '<eos>']\n",
            "Epoch_Loss - 3.057180166244507\n",
            "\n",
            "Epoch - 7 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<eos>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-225-e19cfd4b621a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Clip the gradient value is it exceeds > 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Update the weights values using the gradients we calculated using bp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFgzrtQx_NAs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}